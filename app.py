import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta
import pytz
import io
import base64
import streamlit.components.v1 as components

JST = pytz.timezone("Asia/Tokyo")

EVENT_ARCHIVE_CSV_URL = "https://mksoul-pro.com/showroom/file/sr-event-archive.csv"
EVENT_PAGE_BASE_URL = "https://www.showroom-live.com/event/"
EVENT_ROOM_LIST_API = "https://www.showroom-live.com/api/event/room_list"

HEADERS = {
    "User-Agent": "Mozilla/5.0"
}


# ===============================
# ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§å–å¾—ï¼ˆCSVå›ºå®šï¼‰
# ===============================
@st.cache_data(ttl=600)
def load_events_from_csv():
    df = pd.read_csv(EVENT_ARCHIVE_CSV_URL, dtype=str)

    df["started_at"] = pd.to_numeric(df["started_at"], errors="coerce")
    df["ended_at"] = pd.to_numeric(df["ended_at"], errors="coerce")
    df["is_entry_scope_inner"] = df["is_entry_scope_inner"].str.upper() == "TRUE"

    df.dropna(subset=["event_id", "started_at", "ended_at"], inplace=True)

    now = datetime.now(JST)
    two_weeks_ago_ts = int((now - timedelta(days=14)).timestamp())

    # çµ‚äº†å¾Œ2é€±é–“ä»¥å†… or é–‹å‚¬ä¸­ or é–‹å‚¬äºˆå®šã®ã¿
    df = df[
        (df["ended_at"] >= two_weeks_ago_ts)
    ]

    return df


# ===============================
# å‚åŠ ãƒ«ãƒ¼ãƒ æ•°
# ===============================
def get_total_entries(event_id):
    try:
        res = requests.get(
            EVENT_ROOM_LIST_API,
            params={"event_id": event_id},
            headers=HEADERS,
            timeout=10
        )
        if res.status_code != 200:
            return "N/A"
        return res.json().get("total_entries", 0)
    except Exception:
        return "N/A"


# ===============================
# ãƒ¡ã‚¤ãƒ³
# ===============================
def main():
    st.set_page_config(page_title="SHOWROOM ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§", layout="wide")

    st.markdown("## ğŸ¤ SHOWROOM ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§")

    df = load_events_from_csv()

    if df.empty:
        st.info("è¡¨ç¤ºå¯èƒ½ãªã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    rows = []

    for _, r in df.iterrows():
        rows.append({
            "ã‚¤ãƒ™ãƒ³ãƒˆå": r["event_name"],
            "URL": f"{EVENT_PAGE_BASE_URL}{r['event_url_key']}",
            "å¯¾è±¡": "å¯¾è±¡è€…é™å®š" if r["is_entry_scope_inner"] else "å…¨ãƒ©ã‚¤ãƒãƒ¼",
            "é–‹å§‹": datetime.fromtimestamp(int(r["started_at"]), JST).strftime("%Y/%m/%d %H:%M"),
            "çµ‚äº†": datetime.fromtimestamp(int(r["ended_at"]), JST).strftime("%Y/%m/%d %H:%M"),
            "å‚åŠ ãƒ«ãƒ¼ãƒ æ•°": get_total_entries(r["event_id"])
        })

    df_view = pd.DataFrame(rows)

    # ===== CSV =====
    csv = df_view.drop(columns=["URL"]).to_csv(index=False, encoding="utf-8-sig")
    b64 = base64.b64encode(csv.encode()).decode()

    # ===== HTMLè¡¨ç¤ºï¼ˆè¦‹ãˆæ–¹ç¶­æŒï¼‰=====
    html = """
    <div class="table-wrapper">
    <table>
      <thead>
        <tr>
          <th>ã‚¤ãƒ™ãƒ³ãƒˆå</th>
          <th>å¯¾è±¡</th>
          <th>é–‹å§‹</th>
          <th>çµ‚äº†</th>
          <th>å‚åŠ ãƒ«ãƒ¼ãƒ æ•°</th>
        </tr>
      </thead>
      <tbody>
    """

    for r in rows:
        html += f"""
        <tr>
          <td><a href="{r['URL']}" target="_blank">{r['ã‚¤ãƒ™ãƒ³ãƒˆå']}</a></td>
          <td>{r['å¯¾è±¡']}</td>
          <td>{r['é–‹å§‹']}</td>
          <td>{r['çµ‚äº†']}</td>
          <td>{r['å‚åŠ ãƒ«ãƒ¼ãƒ æ•°']}</td>
        </tr>
        """

    html += f"""
      </tbody>
    </table>
    </div>
    <a href="data:text/csv;base64,{b64}" download="event_list.csv">
      ğŸ“Š ã“ã®å†…å®¹ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    </a>
    """

    components.html(html, height=800, scrolling=False)


if __name__ == "__main__":
    main()
