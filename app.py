import streamlit as st
import requests
from datetime import datetime, timedelta
import time
import pytz
import pandas as pd
import io
import re
import ftplib  # âœ… FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ç”¨
import concurrent.futures
import streamlit.components.v1 as components


# æ—¥æœ¬æ™‚é–“(JST)ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è¨­å®š
JST = pytz.timezone('Asia/Tokyo')

# --- å®šæ•°å®šç¾© ---
# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã«ä½¿ç”¨ã™ã‚‹ãƒ˜ãƒƒãƒ€ãƒ¼
HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
# ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢APIã®URL
API_EVENT_SEARCH_URL = "https://www.showroom-live.com/api/event/search"
# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ ãƒªã‚¹ãƒˆAPIã®URLï¼ˆå‚åŠ ãƒ«ãƒ¼ãƒ æ•°å–å¾—ç”¨ï¼‰
API_EVENT_ROOM_LIST_URL = "https://www.showroom-live.com/api/event/room_list"
# SHOWROOMã®ã‚¤ãƒ™ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã®ãƒ™ãƒ¼ã‚¹URL
EVENT_PAGE_BASE_URL = "https://www.showroom-live.com/event/"
# MKsoulãƒ«ãƒ¼ãƒ ãƒªã‚¹ãƒˆ
ROOM_LIST_URL = "https://mksoul-pro.com/showroom/file/room_list.csv"
# éå»ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’æ ¼ç´ã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®URL
PAST_EVENT_INDEX_URL = "https://mksoul-pro.com/showroom/file/sr-event-archive-list-index.txt"


# ===============================
# ğŸ“± å…±é€šãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–CSSï¼ˆã‚¹ãƒãƒ›ï¼ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå¯¾å¿œï¼‰
# ===============================
st.markdown("""
<style>
/* ---------- ãƒ†ãƒ¼ãƒ–ãƒ«å…±é€š ---------- */
table {
    width: 100%;
    border-collapse: collapse;
    font-size: 14px;
}

/* ---------- ãƒœã‚¿ãƒ³ãƒªãƒ³ã‚¯ ---------- */
.rank-btn-link {
    background: #0b57d0;
    color: white !important;
    border: none;
    padding: 4px 8px;
    border-radius: 4px;
    cursor: pointer;
    text-decoration: none;
    display: inline-block;
    font-size: 12px;
}
.rank-btn-link:hover {
    background: #0949a8;
}

/* ---------- æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œ ---------- */
.table-wrapper {
    overflow-x: auto;
    -webkit-overflow-scrolling: touch;
    border: 1px solid #ddd;
    border-radius: 6px;
    width: 100%;
}

/*
.room-name-ellipsis {
    max-width: 250px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    display: inline-block;
}
*/

/* ---------- ã‚¹ãƒãƒ›ãƒ»ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå¯¾å¿œ ---------- */
@media screen and (max-width: 1024px) {
    table {
        font-size: 12px !important;
    }
    th, td {
        padding: 6px !important;
    }
    .rank-btn-link {
        padding: 6px 8px !important;
        font-size: 13px !important;
    }
    .table-wrapper {
        overflow-x: auto !important;
        display: block !important;
    }
    /* å›ºå®šå¹…ã§æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ã«ã™ã‚‹ */
    .table-wrapper table {
        width: 1080px !important;
    }
}
</style>
""", unsafe_allow_html=True)



# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼: event_id æ­£è¦åŒ–é–¢æ•°ï¼ˆå¤‰æ›´ç‚¹ï¼‰ ---
def normalize_event_id_val(val):
    """
    event_id ã®å‹ã‚†ã‚Œï¼ˆæ•°å€¤ã€æ–‡å­—åˆ—ã€'123.0' ãªã©ï¼‰ã‚’å¸åã—ã¦
    ä¸€è²«ã—ãŸæ–‡å­—åˆ—ã‚­ãƒ¼ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: æ­£è¦åŒ–ã•ã‚ŒãŸæ–‡å­—åˆ— (ä¾‹: "123")ã€ç„¡åŠ¹ãªã‚‰ None ã‚’è¿”ã™
    """
    if val is None:
        return None
    try:
        # numpy / pandas ã®æ•°å€¤å‹ã‚‚æ‰±ãˆã‚‹ã‚ˆã† float ã«ã—ã¦åˆ¤å®š
        # ãŸã ã— 'abc' ã®ã‚ˆã†ãªæ–‡å­—åˆ—ã¯ãã®ã¾ã¾æ–‡å­—åˆ—åŒ–ã—ã¦è¿”ã™
        if isinstance(val, (int,)):
            return str(val)
        if isinstance(val, float):
            if val.is_integer():
                return str(int(val))
            return str(val).strip()
        s = str(val).strip()
        # ã‚‚ã— "123.0" ã®ã‚ˆã†ãªè¡¨è¨˜ãªã‚‰æ•´æ•°ã«å¤‰æ›ã—ã¦æ•´æ•°è¡¨è¨˜ã§è¿”ã™
        if re.match(r'^\d+(\.0+)?$', s):
            return str(int(float(s)))
        # æ™®é€šã®æ•°å­—æ–‡å­—åˆ—ã‚„ã‚­ãƒ¼æ–‡å­—åˆ—ã¯ãƒˆãƒªãƒ ã—ãŸã‚‚ã®ã‚’è¿”ã™
        if s == "":
            return None
        return s
    except Exception:
        try:
            return str(val).strip()
        except Exception:
            return None

# --- ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° ---



# --- FTPãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ ---
def ftp_upload(file_path, content_bytes):
    """FTPã‚µãƒ¼ãƒãƒ¼ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    ftp_host = st.secrets["ftp"]["host"]
    ftp_user = st.secrets["ftp"]["user"]
    ftp_pass = st.secrets["ftp"]["password"]
    with ftplib.FTP(ftp_host) as ftp:
        ftp.login(ftp_user, ftp_pass)
        with io.BytesIO(content_bytes) as f:
            ftp.storbinary(f"STOR {file_path}", f)


def ftp_download(file_path):
    """FTPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰"""
    ftp_host = st.secrets["ftp"]["host"]
    ftp_user = st.secrets["ftp"]["user"]
    ftp_pass = st.secrets["ftp"]["password"]
    with ftplib.FTP(ftp_host) as ftp:
        ftp.login(ftp_user, ftp_pass)
        buffer = io.BytesIO()
        try:
            ftp.retrbinary(f"RETR {file_path}", buffer.write)
            buffer.seek(0)
            return buffer.getvalue().decode('utf-8-sig')
        except Exception:
            return None


def update_archive_file():
    """å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—â†’å¿…è¦é …ç›®ã‚’æŠ½å‡ºâ†’é‡è¤‡é™¤å¤–â†’sr-event-archive.csvã‚’ä¸Šæ›¸ãâ†’ãƒ­ã‚°è¿½è¨˜ï¼‹DL"""
    JST = pytz.timezone('Asia/Tokyo')
    now_str = datetime.now(JST).strftime("%Y/%m/%d %H:%M:%S")

    st.info("ğŸ“¡ ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    statuses = [1, 3, 4]
    new_events = get_events(statuses)

    # âœ… å¿…è¦ãª9é …ç›®ã ã‘æŠ½å‡º
    filtered_events = []
    for e in new_events:
        try:
            filtered_events.append({
                "event_id": e.get("event_id"),
                "is_event_block": e.get("is_event_block"),
                "is_entry_scope_inner": e.get("is_entry_scope_inner"),
                "event_name": e.get("event_name"),
                "image_m": e.get("image_m"),
                "started_at": e.get("started_at"),
                "ended_at": e.get("ended_at"),
                "event_url_key": e.get("event_url_key"),
                "show_ranking": e.get("show_ranking")
            })
        except Exception:
            continue

    new_df = pd.DataFrame(filtered_events)
    if new_df.empty:
        st.warning("æœ‰åŠ¹ãªã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # event_idæ­£è¦åŒ–
    new_df["event_id"] = new_df["event_id"].apply(normalize_event_id_val)
    new_df.dropna(subset=["event_id"], inplace=True)
    new_df.drop_duplicates(subset=["event_id"], inplace=True)

    # æ—¢å­˜ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–å¾—
    st.info("ğŸ’¾ FTPã‚µãƒ¼ãƒãƒ¼ä¸Šã®æ—¢å­˜ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–å¾—ä¸­...")
    existing_csv = ftp_download("/mksoul-pro.com/showroom/file/sr-event-archive.csv")
    if existing_csv:
        old_df = pd.read_csv(io.StringIO(existing_csv), dtype=str)
        old_df["event_id"] = old_df["event_id"].apply(normalize_event_id_val)
    else:
        old_df = pd.DataFrame(columns=new_df.columns)

    # çµåˆï¼‹é‡è¤‡é™¤å¤–
    merged_df = pd.concat([old_df, new_df], ignore_index=True)
    before_count = len(old_df)
    merged_df.drop_duplicates(subset=["event_id"], keep="last", inplace=True)
    after_count = len(merged_df)
    added_count = after_count - before_count  # â†ã“ã®ã¾ã¾ã§OKï¼ˆãƒã‚¤ãƒŠã‚¹ã‚‚è¨±å®¹ï¼‰

    # ä¸Šæ›¸ãã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.info("â˜ï¸ FTPã‚µãƒ¼ãƒãƒ¼ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
    csv_bytes = merged_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    ftp_upload("/mksoul-pro.com/showroom/file/sr-event-archive.csv", csv_bytes)

    # ãƒ­ã‚°è¿½è¨˜
    log_text = f"[{now_str}] æ›´æ–°å®Œäº†: {added_count}ä»¶è¿½åŠ  / åˆè¨ˆ {after_count}ä»¶\n"
    existing_log = ftp_download("/mksoul-pro.com/showroom/file/sr-event-archive-log.txt")
    if existing_log:
        log_text = existing_log + log_text
    ftp_upload("/mksoul-pro.com/showroom/file/sr-event-archive-log.txt", log_text.encode("utf-8"))

    st.success(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ›´æ–°å®Œäº†: {added_count}ä»¶è¿½åŠ ï¼ˆåˆè¨ˆ {after_count}ä»¶ï¼‰")

    # âœ… æ›´æ–°å®Œäº†å¾Œã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³è¿½åŠ 
    st.download_button(
        label="ğŸ“¥ æ›´æ–°å¾Œã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_bytes,
        file_name=f"sr-event-archive_{datetime.now(JST).strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )


@st.cache_data(ttl=600)  # 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿æŒ
def get_events(statuses):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’APIã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚
    å¤‰æ›´ç‚¹: å„ã‚¤ãƒ™ãƒ³ãƒˆè¾æ›¸ã«å–å¾—å…ƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¤ºã™ã‚­ãƒ¼ '_fetched_status' ã‚’è¿½åŠ ã—ã¾ã™ã€‚
    """
    all_events = []
    # é¸æŠã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã”ã¨ã«APIã‚’å©ã
    for status in statuses:
        page = 1
        # 1ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚ãŸã‚Šæœ€å¤§20ãƒšãƒ¼ã‚¸ã¾ã§å–å¾—ã‚’è©¦ã¿ã‚‹
        for _ in range(20):
            params = {"status": status, "page": page}
            try:
                response = requests.get(API_EVENT_SEARCH_URL, headers=HEADERS, params=params, timeout=10)
                response.raise_for_status()  # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
                data = response.json()

                # 'events' ã¾ãŸã¯ 'event_list' ã‚­ãƒ¼ã‹ã‚‰ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—
                page_events = data.get('events', data.get('event_list', []))

                if not page_events:
                    break  # ã‚¤ãƒ™ãƒ³ãƒˆãŒãªã‘ã‚Œã°ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

                # --- ã“ã“ãŒé‡è¦: å„ã‚¤ãƒ™ãƒ³ãƒˆã«å–å¾—å…ƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ³¨å…¥ ---
                for ev in page_events:
                    try:
                        # in-placeã§æ›¸ãè¾¼ã‚“ã§ã—ã¾ã£ã¦å•é¡Œãªã„æƒ³å®š
                        ev['_fetched_status'] = status
                    except Exception:
                        pass

                all_events.extend(page_events)
                page += 1
                time.sleep(0.1) # APIã¸ã®è² è·ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
            except requests.exceptions.RequestException as e:
                st.error(f"ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (status={status}): {e}")
                break
            except ValueError:
                st.error(f"APIã‹ã‚‰ã®JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ (status={status})ã€‚")
                break
    return all_events



@st.cache_data(ttl=600)
def get_past_events_from_files():
    """
    çµ‚äº†(BU)ãƒã‚§ãƒƒã‚¯æ™‚ã«ä½¿ç”¨ã•ã‚Œã‚‹éå»ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã€‚
    ã“ã‚Œã¾ã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ–¹å¼ã§ã¯ãªãã€
    å›ºå®šãƒ•ã‚¡ã‚¤ãƒ« https://mksoul-pro.com/showroom/file/sr-event-archive.csv ã‚’ç›´æ¥èª­ã¿è¾¼ã‚€ã€‚
    """
    all_past_events = pd.DataFrame()
    column_names = [
        "event_id", "is_event_block", "is_entry_scope_inner", "event_name",
        "image_m", "started_at", "ended_at", "event_url_key", "show_ranking"
    ]

    fixed_csv_url = "https://mksoul-pro.com/showroom/file/sr-event-archive.csv"

    try:
        response = requests.get(fixed_csv_url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        csv_text = response.content.decode('utf-8-sig')
        csv_file_like_object = io.StringIO(csv_text)
        df = pd.read_csv(csv_file_like_object, dtype=str)

        # åˆ—åãƒã‚§ãƒƒã‚¯ï¼ˆè¶³ã‚Šãªã„åˆ—ãŒã‚ã‚Œã°è£œã†ï¼‰
        for col in column_names:
            if col not in df.columns:
                df[col] = None
        df = df[column_names]  # åˆ—é †ã‚’æƒãˆã‚‹

        # å‹æ•´å½¢
        df['is_entry_scope_inner'] = df['is_entry_scope_inner'].astype(str).str.lower().str.strip() == 'true'
        df['started_at'] = pd.to_numeric(df['started_at'], errors='coerce')
        df['ended_at'] = pd.to_numeric(df['ended_at'], errors='coerce')
        df.dropna(subset=['started_at', 'ended_at'], inplace=True)
        df['event_id'] = df['event_id'].apply(normalize_event_id_val)
        df.dropna(subset=['event_id'], inplace=True)
        df.drop_duplicates(subset=['event_id'], keep='last', inplace=True)

        # çµ‚äº†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã«çµã‚‹
        now_timestamp = int(datetime.now(JST).timestamp())
        df = df[df['ended_at'] < now_timestamp]

        # âœ… ã‚¤ãƒ™ãƒ³ãƒˆçµ‚äº†æ—¥ãŒæ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆã“ã“ãŒä»Šå›ã®è¿½åŠ ï¼‰
        df.sort_values(by="ended_at", ascending=False, inplace=True, ignore_index=True)

        all_past_events = df.copy()

    except requests.exceptions.RequestException as e:
        st.warning(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—CSVå–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except Exception as e:
        st.warning(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—CSVã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    return all_past_events.to_dict('records')


#@st.cache_data(ttl=300)  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿æŒ
def get_total_entries(event_id):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã®ç·å‚åŠ ãƒ«ãƒ¼ãƒ æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚
    """
    params = {"event_id": event_id}
    try:
        response = requests.get(API_EVENT_ROOM_LIST_URL, headers=HEADERS, params=params, timeout=10)
        # 404ã‚¨ãƒ©ãƒ¼ã¯å‚åŠ è€…æƒ…å ±ãŒãªã„å ´åˆãªã®ã§æ­£å¸¸ç³»ã¨ã—ã¦æ‰±ã†
        if response.status_code == 404:
            return 0
        response.raise_for_status()
        data = response.json()
        # 'total_entries' ã‚­ãƒ¼ã‹ã‚‰å‚åŠ ãƒ«ãƒ¼ãƒ æ•°ã‚’å–å¾—
        return data.get('total_entries', 0)
    except requests.exceptions.RequestException:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ 'N/A' ã‚’è¿”ã™
        return "N/A"
    except ValueError:
        return "N/A"



# âœ… event_id å˜ä½ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒšãƒ¼ã‚¸å˜ä½ã‚‚å«ã‚€ï¼‰
@st.cache_data(ttl=300)
def fetch_room_list_page(event_id: str, page: int):
    """1ãƒšãƒ¼ã‚¸åˆ†ã® room_list ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡ï¼‰"""
    url = f"https://www.showroom-live.com/api/event/room_list?event_id={event_id}&p={page}"
    try:
        res = requests.get(url, headers=HEADERS, timeout=10)
        if res.status_code == 200:
            return res.json().get("list", [])
    except Exception:
        pass
    return []


# --- UIè¡¨ç¤ºé–¢æ•° ---


def get_duration_category(start_ts, end_ts):
    """
    ã‚¤ãƒ™ãƒ³ãƒˆæœŸé–“ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
    """
    duration = timedelta(seconds=end_ts - start_ts)
    if duration <= timedelta(days=3):
        return "3æ—¥ä»¥å†…"
    elif duration <= timedelta(days=7):
        return "1é€±é–“"
    elif duration <= timedelta(days=10):
        return "10æ—¥"
    elif duration <= timedelta(days=14):
        return "2é€±é–“"
    else:
        return "ãã®ä»–"


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="SHOWROOM ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§",
        page_icon="ğŸ¤",
        layout="wide"
    )

    st.markdown(
        "<h1 style='font-size:28px; text-align:left; color:#1f2937;'>ğŸ¤ SHOWROOM ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§</h1>",
        unsafe_allow_html=True
    )

    # ç°¡æ˜“ç‰ˆã®åˆ¶ç´„ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ã‚·ãƒ³ãƒ—ãƒ«ã«è¡¨ç¤º
    # st.markdown("""
    # <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 5px solid #6c757d; margin-bottom: 20px;">
    #     <p style="margin: 0; font-weight: bold; color: #495057;">ğŸ’¡ ç°¡æ˜“ç‰ˆã«æ–¼ã‘ã‚‹åˆ¶ç´„</p>
    #     <ul style="margin: 5px 0 0 0; font-size: 14px; color: #6c757d;">
    #         <li>ä¸€è¦§è¡¨ç¤ºã®ã¿ã®è¡¨ç¤ºã¨ãªã‚Šã¾ã™ã€‚</li>
    #         <li>ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã¯è¤‡æ•°ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚</li>
    #         <li>ã€Œçµ‚äº†ã€ã¯ã€çµ‚äº†æ—¥æ™‚ã‹ã‚‰1ãƒ¶æœˆä»¥å†…ã®ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿å¯¾è±¡ã¨ãªã‚Šã¾ã™ã€‚</li>
    #     </ul>
    # </div>
    # """, unsafe_allow_html=True)

    #st.markdown("<h1 style='font-size:2.5em;'>ğŸ¤ SHOWROOM ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§</h1>", unsafe_allow_html=True)
    st.write("")



    # è¡Œé–“ã¨ä½™ç™½ã®èª¿æ•´
    st.markdown(
        """
        <style>
        /* ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ã®è¡Œé–“ã‚’è©°ã‚ã‚‹ */
        .event-info p, .event-info li, .event-info {
            line-height: 1.7;
            margin-top: 0.0rem;
            margin-bottom: 0.4rem;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ ---
    st.sidebar.header("è¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿")

    # 1ã¤ã ã‘é¸ã¹ã‚‹ã‚ˆã†ã«åˆ¶å¾¡ã™ã‚‹ä»•çµ„ã¿
    def handle_click(key):
        for k in ["use_on_going", "use_upcoming", "use_finished"]:
            if k != key:
                st.session_state[k] = False

    # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æœ¬ä½“ï¼ˆè¦‹ãŸç›®ã¨è¡Œé–“ã‚’ç¶­æŒï¼‰
    use_on_going = st.sidebar.checkbox("é–‹å‚¬ä¸­", key="use_on_going", on_change=handle_click, args=("use_on_going",))
    use_upcoming = st.sidebar.checkbox("é–‹å‚¬äºˆå®š", key="use_upcoming", on_change=handle_click, args=("use_upcoming",))
    use_finished = st.sidebar.checkbox("çµ‚äº†", key="use_finished", on_change=handle_click, args=("use_finished",))

    # å¤‰æ•°ã ã‘æ®‹ã—ã¦å¸¸ã«ã‚ªãƒ•
    use_past_bu = False 

    # é¸æŠã•ã‚ŒãŸæƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹ï¼ˆã“ã‚Œä»¥é™ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå‹•ãã‚ˆã†ã«èª¿æ•´ï¼‰
    status_map = {"use_on_going": 1, "use_upcoming": 3, "use_finished": 4}
    selected_statuses = []
    for k, v in status_map.items():
        if st.session_state.get(k):
            selected_statuses.append(v)

    if not selected_statuses and not use_past_bu:
        st.warning("è¡¨ç¤ºã™ã‚‹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
    
    
    # é¸æŠã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«åŸºã¥ã„ã¦ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—
    # è¾æ›¸ã‚’ä½¿ã£ã¦é‡è¤‡ã‚’ç¢ºå®Ÿã«æ’é™¤
    unique_events_dict = {}

    # --- ã‚«ã‚¦ãƒ³ãƒˆç”¨ã®å¤‰æ•°ã‚’åˆæœŸåŒ–ï¼ˆè¿½åŠ ï¼‰ ---
    fetched_count_raw = 0
    past_count_raw = 0
    fetched_events = []  # å‚ç…§å®‰å…¨ã®ãŸã‚åˆæœŸåŒ–
    past_events = []     # å‚ç…§å®‰å…¨ã®ãŸã‚åˆæœŸåŒ–

    if selected_statuses:
        with st.spinner("ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ä¸­..."):
            fetched_events = get_events(selected_statuses)
            # --- APIå–å¾—åˆ†ã®ã€Œç”Ÿã€ä»¶æ•°ã‚’ä¿æŒï¼ˆå¤‰æ›´ï¼‰ ---
            fetched_count_raw = len(fetched_events)
            for event in fetched_events:
                # --- å¤‰æ›´: event_id ã‚’æ­£è¦åŒ–ã—ã¦è¾æ›¸ã‚­ãƒ¼ã«ã™ã‚‹ ---
                eid = normalize_event_id_val(event.get('event_id'))
                if eid is None:
                    # ç„¡åŠ¹ãªIDã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
                # ã‚¤ãƒ™ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã® event_id ã‚‚æ­£è¦åŒ–ã—ã¦ä¸Šæ›¸ãã—ã¦ãŠãï¼ˆä»¥é™ã®å‡¦ç†ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ï¼‰
                event['event_id'] = eid
                # ãƒ•ã‚§ãƒƒãƒå…ƒï¼ˆAPIï¼‰ã‚’å„ªå…ˆã—ã¦æ ¼ç´ï¼ˆä¸Šæ›¸ãå¯ï¼‰
                unique_events_dict[eid] = event
    
    # --- ã€Œçµ‚äº†(BU)ã€ã®ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    if use_past_bu:
        with st.spinner("éå»ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†ä¸­..."):
            past_events = get_past_events_from_files()
            past_count_raw = len(past_events)

            # âœ… APIã§å–å¾—ã—ãŸã€Œçµ‚äº†ã€ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆstatus=4ï¼‰ã® event_id ä¸€è¦§ã‚’ä½œæˆ
            api_finished_events = []
            try:
                api_finished_events = get_events([4])  # æ˜ç¤ºçš„ã«çµ‚äº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã ã‘å†å–å¾—
            except Exception as ex:
                st.warning(f"çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {ex}")

            api_finished_ids = {
                normalize_event_id_val(e.get("event_id"))
                for e in api_finished_events
                if e.get("event_id")
            }

            # âœ… ã€Œçµ‚äº†(BU)ã€ã‹ã‚‰APIã®ã€Œçµ‚äº†ã€ã‚¤ãƒ™ãƒ³ãƒˆã‚’é™¤å¤–ï¼ˆé‡è¤‡å®Œå…¨æ’é™¤ï¼‰
            filtered_past_events = []
            for e in past_events:
                eid = normalize_event_id_val(e.get("event_id"))
                if eid and eid not in api_finished_ids:
                    filtered_past_events.append(e)

            removed_count = len(past_events) - len(filtered_past_events)
            if removed_count > 0:
                st.info(f"ğŸ§¹ ã€Œçµ‚äº†(BU)ã€ã‹ã‚‰ {removed_count} ä»¶ã®é‡è¤‡ã‚¤ãƒ™ãƒ³ãƒˆã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚")

            past_events = filtered_past_events

            # --- æ­£è¦åŒ–ï¼†è¾æ›¸æ ¼ç´ ---
            for event in past_events:
                eid = normalize_event_id_val(event.get('event_id'))
                if eid is None:
                    continue
                event['event_id'] = eid
                # æ—¢ã« API ã‹ã‚‰å–å¾—ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ä¸Šæ›¸ãã—ãªã„ï¼ˆAPI å´ã‚’å„ªå…ˆï¼‰
                if eid not in unique_events_dict:
                    unique_events_dict[eid] = event


    # è¾æ›¸ã®å€¤ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ã«é€²ã‚€
    all_events = list(unique_events_dict.values())
    
    # âœ… ç‰¹å®šã‚¤ãƒ™ãƒ³ãƒˆã‚’å®Œå…¨é™¤å¤–ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å€™è£œã«ã‚‚æ®‹ã‚‰ãªã„ã‚ˆã†ã«ï¼‰
    all_events = [e for e in all_events if str(e.get("event_id")) != "12151"]
    
    original_event_count = len(all_events)

    # --- å–å¾—å‰ã®åˆè¨ˆï¼ˆç”Ÿï¼‰ä»¶æ•°ã¨ãƒ¦ãƒ‹ãƒ¼ã‚¯ä»¶æ•°ã®å·®åˆ†ã‚’ç®—å‡ºï¼ˆè¿½åŠ ï¼‰ ---
    total_raw = fetched_count_raw + past_count_raw
    unique_total_pre_filter = len(all_events)
    duplicates_removed_pre_filter = max(0, total_raw - unique_total_pre_filter)

    if not all_events:
        st.info("è©²å½“ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()
    else:
        # --- reverseåˆ¶å¾¡ãƒ•ãƒ©ã‚°ã‚’å®šç¾© ---
        # ã€Œçµ‚äº†ã€ã¾ãŸã¯ã€Œçµ‚äº†(BU)ã€ãŒãƒã‚§ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯é™é †ï¼ˆreverse=Trueï¼‰
        # ãã‚Œä»¥å¤–ï¼ˆï¼é–‹å‚¬ä¸­ï¼é–‹å‚¬äºˆå®šã®ã¿ï¼‰ã®å ´åˆã¯æ˜‡é †ï¼ˆreverse=Falseï¼‰
        reverse_sort = (use_finished or use_past_bu)

        # --- é–‹å§‹æ—¥ãƒ•ã‚£ãƒ«ã‚¿ã®é¸æŠè‚¢ã‚’ç”Ÿæˆ ---
        start_dates = sorted(list(set([
            datetime.fromtimestamp(e['started_at'], JST).date() for e in all_events if 'started_at' in e
        ])), reverse=reverse_sort)

        # æ—¥ä»˜ã¨æ›œæ—¥ã®è¾æ›¸ã‚’ä½œæˆ
        start_date_options = {
            d.strftime('%Y/%m/%d') + f"({['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][d.weekday()]})": d
            for d in start_dates
        }

        selected_start_dates = st.sidebar.multiselect(
            "é–‹å§‹æ—¥ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=list(start_date_options.keys())
        )

        # --- çµ‚äº†æ—¥ãƒ•ã‚£ãƒ«ã‚¿ã®é¸æŠè‚¢ã‚’ç”Ÿæˆ ---
        end_dates = sorted(list(set([
            datetime.fromtimestamp(e['ended_at'], JST).date() for e in all_events if 'ended_at' in e
        ])), reverse=reverse_sort)

        end_date_options = {
            d.strftime('%Y/%m/%d') + f"({['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][d.weekday()]})": d
            for d in end_dates
        }

        selected_end_dates = st.sidebar.multiselect(
            "çµ‚äº†æ—¥ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=list(end_date_options.keys())
        )

        # æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿
        duration_options = ["3æ—¥ä»¥å†…", "1é€±é–“", "10æ—¥", "2é€±é–“", "ãã®ä»–"]
        selected_durations = st.sidebar.multiselect(
            "æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=duration_options
        )

        # å¯¾è±¡ã§ãƒ•ã‚£ãƒ«ã‚¿
        target_options = ["å…¨ãƒ©ã‚¤ãƒãƒ¼", "å¯¾è±¡è€…é™å®š"]
        selected_targets = st.sidebar.multiselect(
            "å¯¾è±¡ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=target_options
        )
        

        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        filtered_events = all_events
        
        if selected_start_dates:
            # start_date_options ã‚’å‚ç…§ã™ã‚‹
            selected_dates_set = {start_date_options[d] for d in selected_start_dates}
            filtered_events = [
                e for e in filtered_events
                if 'started_at' in e and datetime.fromtimestamp(e['started_at'], JST).date() in selected_dates_set
            ]
        
        # â–¼â–¼ çµ‚äº†æ—¥ãƒ•ã‚£ãƒ«ã‚¿ã®å‡¦ç†ã‚’è¿½åŠ ï¼ˆã“ã“ã‹ã‚‰è¿½åŠ /ä¿®æ­£ï¼‰ â–¼â–¼
        if selected_end_dates:
            # end_date_options ã‚’å‚ç…§ã™ã‚‹
            selected_dates_set = {end_date_options[d] for d in selected_end_dates}
            filtered_events = [
                e for e in filtered_events
                if 'ended_at' in e and datetime.fromtimestamp(e['ended_at'], JST).date() in selected_dates_set
            ]
        # â–²â–² çµ‚äº†æ—¥ãƒ•ã‚£ãƒ«ã‚¿ã®å‡¦ç†ã‚’è¿½åŠ ï¼ˆã“ã“ã¾ã§è¿½åŠ /ä¿®æ­£ï¼‰ â–²â–²

        if selected_durations:
            filtered_events = [
                e for e in filtered_events
                if get_duration_category(e['started_at'], e['ended_at']) in selected_durations
            ]
        
        if selected_targets:
            target_map = {"å…¨ãƒ©ã‚¤ãƒãƒ¼": False, "å¯¾è±¡è€…é™å®š": True}
            selected_target_values = {target_map[t] for t in selected_targets}
            filtered_events = [
                e for e in filtered_events
                if e.get('is_entry_scope_inner') in selected_target_values
            ]
        
        
        # --- è¡¨ç¤ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ”¹å–„ï¼ˆæ±ç”¨çš„ãªæ–‡è¨€ï¼‰ ---
        filtered_count = len(filtered_events)
        if use_finished and use_past_bu and duplicates_removed_pre_filter > 0:
            st.success(f"{filtered_count}ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚â€»é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãŸå ´åˆã¯1ä»¶ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
        else:
            st.success(f"{filtered_count}ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        
        st.markdown("---")


        # ===============================
        # ä¸€è¦§è¡¨ç¤º & CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        # ===============================
        import streamlit.components.v1 as components
        import pandas as pd
        import base64

        st.markdown("##### ğŸ“‹ ä¸€è¦§è¡¨ç¤º")

        # --- è¿½åŠ ï¼šå‚åŠ ãƒ«ãƒ¼ãƒ æ•°ã‚’ã¾ã¨ã‚ã¦é«˜é€Ÿã§å–å¾—ã™ã‚‹ ---
        event_ids = [e["event_id"] for e in filtered_events]
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            # 10å€‹åŒæ™‚ã«APIã‚’å©ã
            total_entries_list = list(executor.map(get_total_entries, event_ids))
        
        # å–å¾—ã—ãŸçµæœã‚’å„ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¸­ã«ä¿å­˜ã—ã¦ãŠã
        for e, total in zip(filtered_events, total_entries_list):
            e["total_entries_result"] = total
        # ----------------------------------------------

        # --- 1. CSVãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ (å…ƒã®æ–‡å­—åŒ–ã‘ã—ãªã„ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ) ---
        download_data = []
        for e in filtered_events:
            download_data.append({
                "ã‚¤ãƒ™ãƒ³ãƒˆå": e['event_name'],
                "å¯¾è±¡": "å¯¾è±¡è€…é™å®š" if e.get("is_entry_scope_inner") else "å…¨ãƒ©ã‚¤ãƒãƒ¼",
                "é–‹å§‹": datetime.fromtimestamp(e["started_at"], JST).strftime('%Y/%m/%d %H:%M'),
                "çµ‚äº†": datetime.fromtimestamp(e["ended_at"], JST).strftime('%Y/%m/%d %H:%M'),
                "å‚åŠ ãƒ«ãƒ¼ãƒ æ•°": e.get("total_entries_result", 0)
            })

        df_download = pd.DataFrame(download_data)
        # å‰ã«ã€Œå¤§ä¸ˆå¤«ãã†ã€ã¨è¨€ã£ã¦ã„ãŸã ã„ãŸã€Œutf-8-sigã€ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ä½¿ç”¨
        csv_bytes = df_download.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        b64_csv = base64.b64encode(csv_bytes).decode()

        # --- 2. HTMLã®ä½œæˆ (ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒœã‚¿ãƒ³ã‚’ä¸€ä½“åŒ–ã—ã¦éš™é–“ã‚’ç„¡ãã™) ---
        html = f"""
        <style>
        .summary-wrapper {{
            max-height: 80vh;
            overflow-y: auto;
            border: 1px solid #d1d5db;
            /* ä¸‹ã®ãƒœã‚¿ãƒ³ã¨ã®é–“ã«å°‘ã—ã ã‘ä½™ç™½ã‚’ä½œã‚‹å ´åˆã¯ã“ã“ */
            margin-bottom: 0px; 
        }}
        .summary-table {{
            width: 100%;
            border-collapse: separate;
            border-spacing: 0;
            font-size: 0.85rem; 
            font-family: sans-serif;
        }}

        /* --- ã€ä¿®æ­£ã€‘è¡¨ã®ä¸€ç•ªä¸‹ã®ç·šãŒãƒ€ãƒ–ã‚‹ã®ã‚’é˜²ã --- */
        .summary-table tbody tr:last-child td {{
            border-bottom: none;
        }}

        .summary-table thead th {{
            background: #f3f4f6;
            text-align: center;
            padding: 10px 12px;
            border-bottom: 1px solid #d1d5db;
            border-right: 1px solid #d1d5db;
            position: sticky;
            top: 0;
            z-index: 10;
            white-space: nowrap; 
        }}
        .summary-table tbody td {{
            padding: 8px 12px;
            border-bottom: 1px solid #e5e7eb;
            border-right: 1px solid #e5e7eb;
            white-space: nowrap; 
        }}
        .summary-table td:first-child {{
            white-space: normal;
            min-width: 250px;
        }}
        .summary-table tbody td.col-center {{
            text-align: center;
        }}
        .summary-table thead th:last-child,
        .summary-table tbody td:last-child {{
            border-right: none;
        }}

        /* --- ã€ä¿®æ­£ã€‘ãƒœã‚¿ãƒ³ã®ä½ç½®ã®å¾®èª¿æ•´ --- */
        .dl-link {{
            display: inline-flex;
            align-items: center;
            padding: 0.4rem 0.8rem;
            border-radius: 0.5rem;
            color: #31333F;
            background-color: #FFFFFF;
            border: 1px solid #d1d5db;
            text-decoration: none;
            font-size: 0.85rem;
            font-family: sans-serif;
            
            /* ã“ã“ã§è¡¨ã¨ã®è·é›¢ã‚’èª¿æ•´ã—ã¾ã™ï¼ˆ10pxç¨‹åº¦ãŒæ¨™æº–çš„ã§ã™ï¼‰ */
            margin-top: 12px; 
        }}
        .dl-link:hover {{
            border-color: #FF4B4B;
            color: #FF4B4B;
        }}
        </style>

        <div class="summary-wrapper">
            <table class="summary-table">
                <thead>
                    <tr>
                      <th>ã‚¤ãƒ™ãƒ³ãƒˆå</th>
                      <th>å¯¾è±¡</th>
                      <th>é–‹å§‹</th>
                      <th>çµ‚äº†</th>
                      <th>å‚åŠ ãƒ«ãƒ¼ãƒ æ•°</th>
                    </tr>
                </thead>
                <tbody>
        """

        for e in filtered_events:
            html += f"""
                <tr>
                  <td><a href="{EVENT_PAGE_BASE_URL}{e['event_url_key']}" target="_blank">{e['event_name']}</a></td>
                  <td class="col-center">{"å¯¾è±¡è€…é™å®š" if e.get("is_entry_scope_inner") else "å…¨ãƒ©ã‚¤ãƒãƒ¼"}</td>
                  <td class="col-center">{datetime.fromtimestamp(e["started_at"], JST).strftime('%Y/%m/%d %H:%M')}</td>
                  <td class="col-center">{datetime.fromtimestamp(e["ended_at"], JST).strftime('%Y/%m/%d %H:%M')}</td>
                  <td class="col-center">{e.get("total_entries_result", 0)}</td>
                </tr>
            """

        html += f"""
                </tbody>
            </table>
        </div>
        <a class="dl-link" href="data:text/csv;base64,{b64_csv}" download="event_list.csv">
            ğŸ“Š ã“ã®å†…å®¹ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        </a>
        """

        # ãƒœã‚¿ãƒ³ã¾ã§å«ã‚ã¦è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†é«˜ã•ã‚’èª¿æ•´
        components.html(html, height=800, scrolling=False)

            

if __name__ == "__main__":
    main()